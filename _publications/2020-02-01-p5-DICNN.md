---
title: "5 Deeply Integrated Convolutional Neural Networks"
collection: publications
permalink: /publication/2020-02-01-p5-DICNN
# excerpt: '---.'
#date: 2020-02-01
venue: 'Journal 5'
paperurl: 'http://liangdaojun.github.io/files/p5-DICNN.pdf'
citation: 'Liang, Daojun, et al. "Deeply Integrated Convolutional Neural Networks." Journal of Computers 31.1 (2020): 46-56.'

---

[Download](http://liangdaojun.github.io/files/p5-DICNN.pdf)
[Citation](http://liangdaojun.github.io/files/c5-DICNN.bib)

**Abstract**
The ensemble learning system based on neural network requires a large number of networks as the basic classifier, which makes the parameters and calculations of the system increase sharply. Integrating the neural network in depth can not only reduce the parameters and calculations of the network, but also improve the overall network performance. In this paper, a deeply integrated convolutional neural network (DICNN) was proposed, and several different integration methods were proposed for integrated learning of DICNN. The Mixup is used to train the DICNN because it uses multiple samples for training and it can be better combined with DICNN. A series of ablation experiments were done to prove that the training method of Mixup is equivalent to a regularization and data augmentation. Therefore, a different multi-sample training method as variations of the Mixup (Mixup-XL) can be used to train the DICNN.